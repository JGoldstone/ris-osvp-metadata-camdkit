<!DOCTYPE html>
<html lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>OpenTrackIO</title>
<link rel="stylesheet" href="css/style.css">
<link rel="apple-touch-icon" sizes="180x180" href="res/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="res/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="res/favicon-16x16.png">
<link rel="manifest" href="res/site.webmanifest">
<link rel="mask-icon" href="res/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
 </head>
<body>
    <div class="header">
        <div class="headerInner">
            <img src="img/logo_white.svg" class="headerLogo" />
            <h1>OpenTrackIO Documentation v{{version}}</h1>
        </div>
    </div>
    <div class="wrapper">
        <div class="inner">
            <h2>Overview</h2>
            <p>OpenTrackIO is a free and open protocol designed by the RIS OSVP SMPTE group that seeks to improve interoperability in Virtual Production encoding, tracking and robotic systems.</p>
            <p>Virtual Production (VP) encompasses a range of techniques that use camera and lens tracking systems to generate real-time visual effects (VFX) in a render engine. VP encompasses:</p>
            <ul>
                <li>Augmented Reality (AR),</li>
                <li>chromakey (both for live broadcast and 'Simul-Cam' for on-set VFX pre-visualization),</li>
                <li>In-Camera Visual Effects (ICVFX), eXtended Reailty (XR for LED set extensions) and other Mixed Reality (MR) combinations.</li>
            </ul>
            <p>In these Virtual Production examples the camera tracking system sends the pose of the camera, lens modelling and other metadata to a render engine every frame.</p>
            <img src="img/Example_System.svg" />
            <p>In Augmented Reailty (AR) this enables the engine to render virtual objects from the correct camera position and lens to match the real world. In the In-Camera Visual Effect (ICVFX) example, the tracking data is used to generate the correct perspective in the LED wall to create the illusion of depth.</p>
            <p>In Virtual Production it is critical that the camera's video, the tracking and the lens data are synchronised in space and time to accurately reproduce the visual effect. A sample of the OpenTrackIO protocol contains all the required data in the appropriate formats to achieve this.</p>
            
            <h2>OpenTrackIO protocol</h2>
            <p>This documentation is designed for those producing and consuming tracking data. There may be multiple CONSUMERS of a single PRODUCER'S data. In the AR example above, the camera tracking system is the producer and the render engine is the consumer.</p>
            <img src="img/Producer_Consumers.svg" />
            <p>OpenTrackIO defines the schema of JSON samples that contain a wide range of metadata about the device, its transform(s), associated camera and lens. The full schema is given <a href="#schema">below</a> and can be <a href="schema.json" target="_blank">downloaded here</a>.</p>
            <p>All the fields described should be considered optional by the consumer (although for high-quality tracking for Virtual Production see the recommended set in the samples <a href="#recommended">below</a>).</p>
            <p>OpenTrackIO employs the <a href="pdf/OpenLensIO_v1.0.0.pdf" target="_blank">OpenLensIO mathematical lens model</a> for the practical application of spherical lens distortion in Virtual Production.</p>
            
            <h2>Software resources</h2>
            <p>OpenTrackIO's parameters are defined by <a href="https://github.com/SMPTE/ris-osvp-metadata-camdkit" target="_blank">CamDKit</a>. This repo includes examples for <a href="TODO-mosys-f4">generating</a> and <a href="TODO-steve-parser">parsing</a> data.</p>
            <p>A C++ reference implementation of OpenTrackIO is available on <a href="https://github.com/mosys/opentrackio-cpp" target="_blank">Mo-Sys' GitHub</a></p>

            <h2 id="recommended">OpenTrackIO sample</h2>
            <p>It is recommended that metadata samples are transmitted every frame (i.e. to coincide with the video frames from a camera). It provides a snapshot of the status of the tracking system at that instant.</p>
            <button class="collapsible">Recommended minimum VP example</button>
            <div class="content">
                <pre><code>{{examples.recommended_dynamic_example}}</code></pre>
                <p><a href="examples/recommended_dynamic_example.json" target="_blank">Download</a></p>
            </div>

            <h2>Providing additional static data</h2>
            <p>It is recommended that a static metadata object is added to a sample approximately every 2 seconds. This additional metadata describes the context of the samples in the stream, with data that may change - for example - every take, but will not change every frame.</p>
            <button class="collapsible">Recommended minimum VP example with static data</button>
            <div class="content">
                <pre><code>{{examples.recommended_static_example}}</code></pre>
                <p><a href="examples/recommended_static_example.json" target="_blank">Download</a></p>
            </div>

            <h2>Complete sample</h2>
            <p>OpenTrackIO defines many more options and fields and these should be parsed where appropriate by the consumer. Custom fields can also be added as shown (although these will require specific producer / consumer negotiation)</p>
            <button class="collapsible">Complete example sample with static data</button>
            <div class="content">
                <pre><code>{{examples.complete_static_example}}</code></pre>
                <p><a href="examples/complete_static_example.json" target="_blank">Download</a></p>
            </div>
            
            <h2>Transport recommendations</h2>
            <p>It is recommended that OpenTrackIO samples be encapsulated in a network packet for ease of wired or wireless transmission in a production environment. A sample is a JSON object that can be encoded in CBOR (a lossless binary JSON compression format) and then wrapped in an RTP packet for transmission over UDP.</p>
            <img src="img/RTP_Transport.svg">
            <p>Further encapsulation is then possible if required with SMPTE 2110-41 and packets can be timestamped with PTP. Unicast or multicast transmission should be supported by an OpenTrackIO producer.</p>

            <h2>Description of all fields</h2>
            <button class="collapsible">Description of fields</button>
            <div class="content">
                <table>
                    <tr><th>Parameter</th><th>Section</th><th>Sampling</th><th>Description</th><th>Units</th><th>Constraints</th></tr>
                    {% for field in fields %}
                    <tr><td>{{field.canonical_name}}</td><td>{{field.section}}</td><td>{{field.sampling}}</td><td>{{field.description}}</td><td>{{field.units}}</td><td>{{field.constraints}}</td></tr>
                    {% endfor %}
                </table>
            </div>

            <h2 id="schema">JSON schema</h2>
            <p><a href="schema.json" target="_blank">This JSON Schema</a> can be used to validate OpenTrackIO samples</p>
            <button class="collapsible">OpenTrackIO schema</button>
            <div class="content"><pre><code>{{schema}}</code></pre></div>
        </div>
    </div>
    <div class="footer">
        <div class="inner">
            <p><strong>Authored by SMPTE RIS OSVP</strong></p>
            <p>The OpenTrackIO documentation is generated by <a href="https://github.com/SMPTE/ris-osvp-metadata-camdkit" target="_blank">CamDKit</a></p>
            <p>Lead author: <a href="mailto:info@mo-sys.com">James Uren</a>, Mo-Sys</p>
        </div>
    </div>
    
<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;
    
    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
          content.style.display = "none";
        } else {
          content.style.display = "block";
        }
      });
    }
</script>
</body>
</html>
